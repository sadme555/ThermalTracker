# test_dataset.py
"""
çº¢å¤–å°ç›®æ ‡æ•°æ®é›†æµ‹è¯•è„šæœ¬ - ä¿®å¤ç‰ˆæœ¬
"""

import os
import sys
import torch
from pathlib import Path
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib import font_manager
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def setup_environment():
    """è®¾ç½®ç¯å¢ƒå¹¶æ£€æŸ¥ä¾èµ–"""
    print("âœ“ æˆåŠŸå¯¼å…¥æ‰€æœ‰æ¨¡å—")
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ç›®å½•å†…å®¹: {os.listdir('.')}")
    return True

def test_config():
    """æµ‹è¯•é…ç½®ç³»ç»Ÿ"""
    print("\nâ–¶ æ‰§è¡Œ é…ç½®æµ‹è¯•...")
    try:
        from config import get_default_config
        config = get_default_config()
        print("âœ“ æˆåŠŸåˆ›å»ºé…ç½®å®ä¾‹")
        
        # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
        dataset_cfg = config.data.dataset
        print(f"æ ¹è·¯å¾„: {dataset_cfg.root_path}")
        print(f"å›¾åƒè·¯å¾„: {dataset_cfg.image_path}")
        print(f"æ ‡æ³¨è·¯å¾„: {dataset_cfg.annotation_path}")
        print(f"åˆ’åˆ†è·¯å¾„: {dataset_cfg.split_path}")
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        print(f"æ ¹è·¯å¾„å­˜åœ¨: {dataset_cfg.root_path.exists()}")
        print(f"å›¾åƒè·¯å¾„å­˜åœ¨: {dataset_cfg.image_path.exists()}")
        print(f"æ ‡æ³¨è·¯å¾„å­˜åœ¨: {dataset_cfg.annotation_path.exists()}")
        print(f"åˆ’åˆ†è·¯å¾„å­˜åœ¨: {dataset_cfg.split_path.exists()}")
        
        # æ£€æŸ¥æ–‡ä»¶
        if dataset_cfg.annotation_path.exists():
            annotation_files = list(dataset_cfg.annotation_path.glob("*.json"))
            print(f"æ ‡æ³¨æ–‡ä»¶: {[f.name for f in annotation_files]}")
        
        if dataset_cfg.split_path.exists():
            split_files = list(dataset_cfg.split_path.glob("*.txt"))
            print(f"åˆ’åˆ†æ–‡ä»¶: {[f.name for f in split_files]}")
        
        if dataset_cfg.image_path.exists():
            image_dirs = list(dataset_cfg.image_path.iterdir())
            print(f"å›¾åƒå­ç›®å½•ç¤ºä¾‹: {[d.name for d in image_dirs[:3]]}")
        
        print("âœ“ é…ç½®æµ‹è¯• é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âœ— é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_coco_annotations():
    """æµ‹è¯•COCOæ ‡æ³¨æ–‡ä»¶"""
    print("\nâ–¶ æ‰§è¡Œ COCOæ ‡æ³¨æµ‹è¯•...")
    try:
        from pycocotools.coco import COCO
        from config import get_default_config
        
        config = get_default_config()
        dataset_cfg = config.data.dataset
        
        # æµ‹è¯•è®­ç»ƒæ ‡æ³¨æ–‡ä»¶
        train_annotation_path = dataset_cfg.get_annotation_path('train')
        print(f"âœ“ åŠ è½½COCOæ ‡æ³¨: {train_annotation_path}")
        
        coco = COCO(train_annotation_path)
        
        # è·å–å›¾åƒå’Œç±»åˆ«ä¿¡æ¯
        image_ids = coco.getImgIds()
        category_ids = coco.getCatIds()
        categories = coco.loadCats(category_ids)
        
        print(f"âœ“ æ‰¾åˆ° {len(image_ids)} å¼ å›¾åƒ")
        print(f"âœ“ æ‰¾åˆ° {len(categories)} ä¸ªç±»åˆ«:")
        for cat in categories:
            print(f"  - {cat['name']} (id: {cat['id']})")
        
        # æ£€æŸ¥ç¬¬ä¸€å¼ å›¾åƒ
        if len(image_ids) > 0:
            img_info = coco.loadImgs(image_ids[0])[0]
            print(f"âœ“ ç¬¬ä¸€å¼ å›¾åƒä¿¡æ¯: {img_info}")
        
        print("âœ“ COCOæ ‡æ³¨æµ‹è¯• é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âœ— COCOæ ‡æ³¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_dataset_loading():
    """æµ‹è¯•æ•°æ®é›†åŠ è½½ - ä¿®å¤ç‰ˆæœ¬"""
    print("\nâ–¶ æ‰§è¡Œ æ•°æ®é›†åŠ è½½æµ‹è¯•...")
    try:
        from config import get_default_config
        from datasets.infrared_small_target import build_infrared_dataset
        
        print("âœ“ å¼€å§‹æµ‹è¯•æ•°æ®é›†åŠ è½½...")
        
        # è·å–é…ç½®
        config = get_default_config()
        
        # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
        dataset_cfg = config.data.dataset
        print("æ£€æŸ¥æ•°æ®é›†è·¯å¾„...")
        print(f"rootè·¯å¾„: {dataset_cfg.root_path} - å­˜åœ¨: {dataset_cfg.root_path.exists()}")
        if dataset_cfg.root_path.exists():
            print(f"  å†…å®¹: {[item.name for item in dataset_cfg.root_path.iterdir()]}")
        
        print(f"imagesè·¯å¾„: {dataset_cfg.image_path} - å­˜åœ¨: {dataset_cfg.image_path.exists()}")
        if dataset_cfg.image_path.exists():
            print(f"  å†…å®¹: {[item.name for item in list(dataset_cfg.image_path.iterdir())[:3]]}")
        
        print(f"annotationsè·¯å¾„: {dataset_cfg.annotation_path} - å­˜åœ¨: {dataset_cfg.annotation_path.exists()}")
        if dataset_cfg.annotation_path.exists():
            print(f"  å†…å®¹: {[item.name for item in list(dataset_cfg.annotation_path.iterdir())[:3]]}")
        
        print(f"splitsè·¯å¾„: {dataset_cfg.split_path} - å­˜åœ¨: {dataset_cfg.split_path.exists()}")
        if dataset_cfg.split_path.exists():
            print(f"  å†…å®¹: {[item.name for item in list(dataset_cfg.split_path.iterdir())[:3]]}")
        
        # ä½¿ç”¨æ­£ç¡®çš„å‡½æ•°æ„å»ºæ•°æ®é›†
        train_annotation_path = dataset_cfg.get_annotation_path('train')
        print(f"åŠ è½½æ ‡æ³¨æ–‡ä»¶: {train_annotation_path}")
        
        # æ„å»ºæ•°æ®é›†
        dataset = build_infrared_dataset(config, is_train=True)
        
        print(f"æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(dataset)} å¼ å›¾åƒ")
        
        # è·å–ç±»åˆ«ä¿¡æ¯
        if hasattr(dataset, 'class_names'):
            print(f"ç±»åˆ«ä¿¡æ¯: {dataset.class_names}")
        elif hasattr(dataset, 'categories'):
            print(f"ç±»åˆ«ä¿¡æ¯: {[cat['name'] for cat in dataset.categories]}")
        
        print(f"âœ“ æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬
        if len(dataset) > 0:
            print(f"åŠ è½½å›¾åƒ 0")
            img, target = dataset[0]
            
            print(f"âœ“ æˆåŠŸåŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬")
            print(f"  å›¾åƒç±»å‹: {type(img)}")
            print(f"  å›¾åƒå½¢çŠ¶: {img.shape}")
            print(f"  ç›®æ ‡é”®: {list(target.keys())}")
            print(f"  è¾¹ç•Œæ¡†æ•°é‡: {len(target['boxes'])}")
            
            if len(target['boxes']) > 0:
                print(f"  ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡†: {target['boxes'][0]}")
                print(f"  æ ‡ç­¾: {target['labels']}")
        
        print("âœ“ æ•°æ®é›†åŠ è½½æµ‹è¯• é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®é›†åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def visualize_sample():
    """å¯è§†åŒ–æ ·æœ¬ - ä¿®å¤ç‰ˆæœ¬"""
    print("\nâ–¶ æ‰§è¡Œ å¯è§†åŒ–æµ‹è¯•...")
    try:
        from config import get_default_config
        from datasets.infrared_small_target import build_infrared_dataset
        
        print("æ£€æŸ¥æ•°æ®é›†è·¯å¾„...")
        config = get_default_config()
        dataset_cfg = config.data.dataset
        
        print(f"rootè·¯å¾„: {dataset_cfg.root_path} - å­˜åœ¨: {dataset_cfg.root_path.exists()}")
        if dataset_cfg.root_path.exists():
            print(f"  å†…å®¹: {[item.name for item in dataset_cfg.root_path.iterdir()]}")
        
        print(f"imagesè·¯å¾„: {dataset_cfg.image_path} - å­˜åœ¨: {dataset_cfg.image_path.exists()}")
        if dataset_cfg.image_path.exists():
            print(f"  å†…å®¹: {[item.name for item in list(dataset_cfg.image_path.iterdir())[:3]]}")
        
        print(f"annotationsè·¯å¾„: {dataset_cfg.annotation_path} - å­˜åœ¨: {dataset_cfg.annotation_path.exists()}")
        if dataset_cfg.annotation_path.exists():
            print(f"  å†…å®¹: {[item.name for item in list(dataset_cfg.annotation_path.iterdir())[:3]]}")
        
        print(f"splitsè·¯å¾„: {dataset_cfg.split_path} - å­˜åœ¨: {dataset_cfg.split_path.exists()}")
        if dataset_cfg.split_path.exists():
            print(f"  å†…å®¹: {[item.name for item in list(dataset_cfg.split_path.iterdir())[:3]]}")
        
        # ä½¿ç”¨æ­£ç¡®çš„å‡½æ•°æ„å»ºæ•°æ®é›†
        train_annotation_path = dataset_cfg.get_annotation_path('train')
        print(f"åŠ è½½æ ‡æ³¨æ–‡ä»¶: {train_annotation_path}")
        
        dataset = build_infrared_dataset(config, is_train=True)
        
        print(f"æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(dataset)} å¼ å›¾åƒ")
        
        if hasattr(dataset, 'class_names'):
            print(f"ç±»åˆ«ä¿¡æ¯: {dataset.class_names}")
        elif hasattr(dataset, 'categories'):
            print(f"ç±»åˆ«ä¿¡æ¯: {[cat['name'] for cat in dataset.categories]}")
        
        # å¯è§†åŒ–ç¬¬ä¸€ä¸ªæ ·æœ¬
        if len(dataset) > 0:
            print(f"åŠ è½½å›¾åƒ 0")
            img, target = dataset[0]
            
            # è½¬æ¢ä¸ºnumpyç”¨äºå¯è§†åŒ–
            if torch.is_tensor(img):
                img_np = img.permute(1, 2, 0).numpy()
                # åæ ‡å‡†åŒ–
                mean = np.array(config.data.image_mean)
                std = np.array(config.data.image_std)
                img_np = img_np * std + mean
                img_np = np.clip(img_np, 0, 1)
            else:
                img_np = img
            
            # åˆ›å»ºå¯è§†åŒ–
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))
            ax.imshow(img_np)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            if 'boxes' in target and len(target['boxes']) > 0:
                boxes = target['boxes']
                labels = target['labels']
                
                for i, (box, label) in enumerate(zip(boxes, labels)):
                    if torch.is_tensor(box):
                        box = box.numpy()
                    if torch.is_tensor(label):
                        label = label.item()
                    
                    # è¾¹ç•Œæ¡†åæ ‡ [x1, y1, x2, y2]
                    x1, y1, x2, y2 = box
                    width = x2 - x1
                    height = y2 - y1
                    
                    # åˆ›å»ºçŸ©å½¢æ¡†
                    rect = patches.Rectangle(
                        (x1, y1), width, height,
                        linewidth=2, edgecolor='red', facecolor='none'
                    )
                    ax.add_patch(rect)
                    
                    # æ·»åŠ æ ‡ç­¾
                    class_name = f"class_{label}"
                    if hasattr(dataset, 'class_names') and label < len(dataset.class_names):
                        class_name = dataset.class_names[label]
                    
                    ax.text(x1, y1 - 5, class_name, 
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.7),
                           color='white', fontsize=8)
            
            ax.set_title('çº¢å¤–å°ç›®æ ‡æ£€æµ‹æ ·æœ¬', fontsize=16, pad=20)
            ax.axis('off')
            plt.tight_layout()
            
            # ä¿å­˜å›¾åƒ
            plt.savefig('dataset_sample.png', dpi=150, bbox_inches='tight')
            print("âœ“ æ ·æœ¬å›¾åƒå·²ä¿å­˜ä¸º dataset_sample.png")
            
            # æ˜¾ç¤ºå›¾åƒ
            plt.show()
        
        print("âœ“ å¯è§†åŒ–æµ‹è¯• é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âœ— å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 50)
    print("å¼€å§‹æµ‹è¯•çº¢å¤–å°ç›®æ ‡æ•°æ®é›†")
    print("=" * 50)
    
    # è®¾ç½®ç¯å¢ƒ
    if not setup_environment():
        return
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        test_config,
        test_coco_annotations,
        test_dataset_loading,
        visualize_sample
    ]
    
    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"âœ— æµ‹è¯• {test.__name__} æ‰§è¡Œå¤±è´¥: {e}")
            results.append(False)
    
    print("\n" + "=" * 50)
    
    # è¾“å‡ºç»“æœ
    if all(results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! æ•°æ®é›†å‡†å¤‡å°±ç»ªã€‚")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
    
    print("=" * 50)

if __name__ == '__main__':
    main()