# test_deformable_detr_memory_safe.py
"""
å†…å­˜å®‰å…¨çš„Deformable DETRæµ‹è¯•
"""

import torch
import sys
import os
import gc

sys.path.append(os.path.dirname(os.path.abspath(__file__)))


def test_memory_safe():
    """å†…å­˜å®‰å…¨æµ‹è¯•"""
    print("=" * 60)
    print("Memory Safe Deformable DETR Test")
    print("=" * 60)
    
    try:
        from config import get_default_config
        from models.deformable_detr import DeformableDETR
        
        # è·å–é…ç½®
        config = get_default_config()
        print("âœ“ Configuration loaded")
        
        # è¿›ä¸€æ­¥å‡å°‘é…ç½®ä»¥ç¡®ä¿å†…å­˜å®‰å…¨
        config.model.num_queries = 30
        config.model.hidden_dim = 192
        config.model.num_encoder_layers = 2
        config.model.num_decoder_layers = 2
        
        print(f"  num_queries: {config.model.num_queries}")
        print(f"  hidden_dim: {config.model.hidden_dim}")
        print(f"  layers: {config.model.num_encoder_layers} encoder, {config.model.num_decoder_layers} decoder")
        
        # åˆ›å»ºæ¨¡å‹
        model = DeformableDETR(config.model)
        print("âœ“ Model created with config")
        
        # æµ‹è¯•è¾“å…¥ - ä½¿ç”¨å°å°ºå¯¸
        x = torch.randn(1, 3, 256, 320)
        print(f"Input shape: {x.shape}")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = model(x)
        
        print("âœ“ Forward pass successful")
        print(f"Output keys: {list(outputs.keys())}")
        
        # éªŒè¯è¾“å‡ºæ ¼å¼
        assert 'pred_logits' in outputs, "Missing pred_logits"
        assert 'pred_boxes' in outputs, "Missing pred_boxes"
        
        pred_logits = outputs['pred_logits']
        pred_boxes = outputs['pred_boxes']
        
        print(f"pred_logits: {pred_logits.shape}")
        print(f"pred_boxes: {pred_boxes.shape}")
        
        # éªŒè¯å½¢çŠ¶
        assert pred_logits.shape[0] == 1, f"Batch size should be 1, got {pred_logits.shape[0]}"
        assert pred_logits.shape[1] == config.model.num_queries, \
            f"Query number mismatch: expected {config.model.num_queries}, got {pred_logits.shape[1]}"
        assert pred_logits.shape[2] == config.model.num_classes + 1, \
            f"Class number mismatch: expected {config.model.num_classes + 1}, got {pred_logits.shape[2]}"
        
        assert pred_boxes.shape[0] == 1, f"Batch size should be 1, got {pred_boxes.shape[0]}"
        assert pred_boxes.shape[1] == config.model.num_queries, \
            f"Query number mismatch: expected {config.model.num_queries}, got {pred_boxes.shape[1]}"
        assert pred_boxes.shape[2] == 4, f"Should predict 4 box coordinates, got {pred_boxes.shape[2]}"
        
        # æ¸…ç†å†…å­˜
        del model, outputs, x
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        print("âœ“ Config integration test passed!")
        return True
        
    except Exception as e:
        print(f"âœ— Config integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_progressive_complexity():
    """æ¸è¿›å¤æ‚åº¦æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("Progressive Complexity Test")
    print("=" * 60)
    
    try:
        from config import get_default_config
        from models.deformable_detr import DeformableDETR
        
        # æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„é…ç½®
        complexity_levels = [
            {'name': 'Level 1', 'queries': 20, 'dim': 128, 'layers': 2, 'size': (224, 288)},
            {'name': 'Level 2', 'queries': 40, 'dim': 192, 'layers': 3, 'size': (320, 400)},
            {'name': 'Level 3', 'queries': 60, 'dim': 256, 'layers': 4, 'size': (416, 512)},
        ]
        
        for level in complexity_levels:
            print(f"\nâ–¶ Testing {level['name']}:")
            
            config = get_default_config()
            config.model.num_queries = level['queries']
            config.model.hidden_dim = level['dim']
            config.model.num_encoder_layers = level['layers']
            config.model.num_decoder_layers = level['layers']
            
            model = DeformableDETR(config.model)
            
            height, width = level['size']
            x = torch.randn(1, 3, height, width)
            
            with torch.no_grad():
                outputs = model(x)
            
            print(f"  Input: {x.shape}")
            print(f"  Output: logits={outputs['pred_logits'].shape}, boxes={outputs['pred_boxes'].shape}")
            
            # éªŒè¯
            assert outputs['pred_logits'].shape[1] == level['queries']
            assert outputs['pred_boxes'].shape[1] == level['queries']
            
            # æ¸…ç†
            del model, outputs, x
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            print(f"  âœ“ {level['name']} passed")
        
        print("\nâœ“ All progressive complexity tests passed!")
        return True
        
    except Exception as e:
        print(f"âœ— Progressive complexity test failed: {e}")
        return False


def main():
    """è¿è¡Œå†…å­˜å®‰å…¨æµ‹è¯•"""
    print("Running memory-safe Deformable DETR tests...")
    
    tests = [
        test_memory_safe,
        test_progressive_complexity
    ]
    
    results = []
    for test in tests:
        try:
            # åœ¨æ¯ä¸ªæµ‹è¯•å‰æ¸…ç†å†…å­˜
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            result = test()
            results.append(result)
        except Exception as e:
            print(f"âœ— Test {test.__name__} crashed: {e}")
            results.append(False)
    
    print("\n" + "=" * 60)
    print("TEST RESULTS:")
    for i, (test, result) in enumerate(zip(tests, results)):
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"  {i+1}. {test.__name__}: {status}")
    
    if all(results):
        print("\nğŸ‰ ALL MEMORY-SAFE TESTS PASSED!")
        print("The model works correctly with memory-optimized configurations.")
        print("You can now proceed to implement loss functions.")
        return True
    else:
        print("\nâŒ SOME TESTS FAILED!")
        print("Consider using even smaller configurations for your hardware.")
        return False


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)